---
title: "ESMA 6205: Homework 1"
author: "Alejandro Ouslan"
format:
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
    fig-align: "center"
---

# Instructions

Homework should be presented in a clear manner, not scratch notes paper will be allow. The home-
work solution format will be .docx, .doc and .pdf. You can also add your code as part of the supple-
mental material. You must include (if any) your code, but do not include a screenshot of the software
input/output. Outputs may contain irrelevant information for the purpose of the question and can lead
to a wrong interpretation. To be consider for full credit it will need to submitted before the due date.

# Definition:

1. **Simple Linear regression:** Is the best linear representation of the data $Y$ give the data $X$
2. **Gauss-Markov Model:** It is matrix representation of the data $Y$ and $X$.
3. **Design Matrix $X$**: Is the Matrix representation of the data $X$.
4. **Properties of a projection Matrix $P_{X}$** It is the matrix containing all the fited values of the model.

# Problem 2 
- When asked to state the simple linear regression model, a student wrote it as follows: $E[Y_i] = \beta_0 + \beta_1 x_i + \epsilon_i$ Do you agree?

- **Answer:** Yes, the model contains an intercept $\beta_0$ and a single predictor $x_i$ with a slope $\beta_1$ and an error term $\epsilon_i$.

# Problem 3
- Evaluate the following statement: "For the least squares method to be fully valid, it is required
that the distribution of $Y$ be normal."

- **Answer:** No, it is not required but it does simplify the analysis. 

# Problem 4
- A person states that $\hat{\beta}_0$ and $\hat{\beta_1}$, in the fitted regression function can be estimated by the method of least squares. Comment.

- **Answer:** Yes, the least squares method is used to estimate the coefficients of the model.

# Problem 5 
- The director of admissions of a small college selected 120 students at random from the new freshman class in a study to determine whether a student’s 
grade point average (GPA) at the end of the freshman year (Y ) can be predicted from the ACT test score (X). The dataset for this study is in call 
`CH01PR19.txt` you can download it from the authors website. Assume that the first-order regression model is appropriate.

```{python}
import numpy as np
from sklearn import linear_model
import matplotlib.pyplot as plt
```

1. Obtain the least squares estimates of $\beta_0$ and $\beta_1$, and state the estimated regression function. 

- $\beta_0$ is $2.114$ and $\beta_1$ is $0.0388$. Thes regression function is $\hat{y} = 2.114 + 0.0388x_i$

```{python}
data = np.loadtxt("CH01PR19.txt")
y,x,n = data.T[0].reshape(-1,1), data.T[1].reshape(-1,1), len(data)
X = np.column_stack((np.ones(n), x))
beta_hat = np.linalg.pinv(X.T @ X) @ X.T @ y 
print(beta_hat)
```

2. Plot the estimated regression function and the data. Does the estimated regression function appear to fit the data well?

- The fitted line does not seem to fit well the data given that the scatter plot shows that the observations are very scattered.

```{python}
plt.scatter(x, y)
plt.plot(x, X @ beta_hat)
plt.show()
```

3. Obtain a point estimate of the mean freshman GPA for students with Act Test Score $X = 30$. 

- $3.279$

```{python}
y_hat = beta_hat[0] + beta_hat[1] * 30
print(y_hat)
```

4. What is the point estimate of the change in the mean response when the entrance test score increases by one point?

- $0.0388$


5. Obtain the residuals $\hat{\epsilon}$. Do they sum to zero?

- yes (Note: due to rounding error of computers the sum is not exacly zero but is very very close to it)

```{python}
residuals = y - X @ beta_hat
print(residuals.sum())
```

6. Compute $y^T(I - P_X)y$. What this value call?

- This value is called the sum of squares of the residuals.

```{python}
P_X = X @ np.linalg.pinv(X.T @ X) @ X.T
print(y.T @ (np.identity(n) - P_X) @ y)
```
7. Compute $y(I - \frac{1}{n}\begin{bmatrix}1\end{bmatrix}\begin{bmatrix}1\end{bmatrix}^T)$. What this value call?

- This value is called the sum of squares of the response.

```{python}
print(y.T @ (np.identity(n) - (1/n) * np.ones((n,1)) @ np.ones((n,1)).T) @ y)
```


8. Estimate $\sigma^2$ and $\sigma$. 


```{python}
sigma_hat = residuals.T @ residuals / (n - 2)
print(sigma_hat)
```

9. Compute $y^Ty$

```{python}
print(y.T @ y)
```

10. Compute $P_Xy$. Compare you results with part (b)

```{python}
print(P_X @ y)
```

# Problem 6

- Sixteen batches of the plastic were made, and from each batch one test item was molded. Each
test item was randomly assigned to one of the four predetermined time levels, and the hardness
was measured after the assigned elapsed time. The results are shown below; $X$ is the elapsed time
in hours, and $Y$ is hardness in Brinell units. Assume that the first-order regression model (1.1) is
appropriate.

1. Obtain the estimates regression function. Plot the etimated regression function and the data. Does 
a linear regression function appear to give a good fit hear

```{python}
data = np.loadtxt("CH01PR22.txt")
y,x,n = data.T[0].reshape(-1,1), data.T[1].reshape(-1,1), len(data)
X = np.column_stack((np.ones(n), x))
beta_hat = np.linalg.pinv(X.T @ X) @ X.T @ y
print(beta_hat)
```


2. Obtain a point estimate of the mean hardness when $X=40$ hours. 

```{python}
y_hat = beta_hat[0] + beta_hat[1] * 40
print(y_hat)
```

3. Obtain a point estijmate of the change in mean hardness when $X$ increases by $1$ hour.

```{python}
print(beta_hat[1])
```

4. obtain the residuals $\hat{\epsilon}$. Do they sum to zero?

```{python}
residuals = y - X @ beta_hat
print(residuals.sum())
```

5. Compute $y^T(I - P_X)y$. What this value call?

```{python}
P_X = X @ np.linalg.pinv(X.T @ X) @ X.T
print(y.T @ (np.identity(n) - P_X) @ y)
```

6. Compute $y(I - \frac{1}{n}\begin{bmatrix}1\end{bmatrix}\begin{bmatrix}1\end{bmatrix}^T)$. What this value call?

```{python}
print(y.T @ (np.identity(n) - (1/n) * np.ones((n,1)) @ np.ones((n,1)).T) @ y)
```

7. Estimate $\sigma^2$ and $\sigma$. 

```{python}
sigma_hat = residuals.T @ residuals / (n - 2)
print(sigma_hat)
```

8. Compute $y^Ty$

```{python}
print(y.T @ y)
```

9. Compute $P_Xy$. Compare you results with part (b)

```{python}
print(P_X @ y)
```

10. suppose one test item was molded from a single batch of plastic and the hardness of this one
item was measured at 16 different points in time. Would the error term in the regression model
for this case still reflect the same effects as for the experiment initially described? Would you
expect the error terms for the different points in time to be uncorrelated? Discuss.

- The error term would still reflect the same effects as for the experiment initially described.


# Problem 7 
A student working on a summer internship in the economic research department of a large corpo-
ration studied the relation between sales of a product (Y , in million dollars) and population (X,
in million persons) in the firm’s 50 marketing districts. The normal error regression model (2.1)
was employed. The student first wished to test whether or not a linear association between Y and
X existed. The student accessed a simple linear regression program and obtained the following
information on the regression coefficients:

1. he student concluded from these results that there is a linear association between Y and X.
Is the conclusion warranted? What is the implied level of significance?

- The conclusion is warranted given that $0$ is not in the confidence interval of the slope. The level of significance is $0.05$.

2. Someone questioned the negative lower confidence limit for the intercept, pointing out that
dollar sales cannot be negative even if the population in a district is zero. Discuss

- Given that 0 is not in the confidence interval of the intercept, the negative lower confidence limit is not a problem.
